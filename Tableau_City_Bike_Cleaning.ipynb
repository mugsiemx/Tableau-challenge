{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4610b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import requests, io, zipfile, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4ac5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format of url = \"https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip\"\n",
    "url_base = 'https://s3.amazonaws.com/tripdata/'\n",
    "\n",
    "root = 'Resources'\n",
    "\n",
    "result_files = []\n",
    "rename_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e125ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip\n",
      "2013-07 - Citi Bike trip data.csv\n"
     ]
    }
   ],
   "source": [
    "# files set up by month, get by 4 digit year and 2 digit month\n",
    "d = dt.date.today()\n",
    "# url_year = d.year\n",
    "# url_month = d.month\n",
    "\n",
    "url_year = 2013\n",
    "url_month = 7\n",
    "url_file_prefix = f'{url_year:04d}{url_month:02d}'\n",
    "new_file = url_file_prefix + '.csv'\n",
    "# url_file_prefix\n",
    "\n",
    "# directory files same through 2016, changed for 2017\n",
    "url_file_2016 = '-citibike-tripdata.zip'\n",
    "url_file_2017 = '-citibike-tripdata.csv.zip'\n",
    "\n",
    "# do not save folders\n",
    "substring = 'citibike-tripdata.csv'\n",
    "\n",
    "# build the proper url to get data from files in the directory\n",
    "if url_year >= 2017:\n",
    "    url = url_base + url_file_prefix + url_file_2017\n",
    "else:\n",
    "    url = url_base + url_file_prefix + url_file_2016\n",
    "print(url) \n",
    "\n",
    "r = requests.get(url)\n",
    "un_zipped = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "with un_zipped as zf:\n",
    "    for file in zf.namelist():\n",
    "        print(file)\n",
    "        # not in root directory, pass, otherwise save\n",
    "        if file.startswith('_'):\n",
    "            pass\n",
    "        else:\n",
    "            zf.extract(file, root)                        \n",
    "            result_files.append(file)\n",
    "            rename_files.append(new_file)\n",
    "\n",
    "\n",
    "#    ## WORKING CODE\n",
    "# r = requests.get(url)\n",
    "# un_zipped = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "# with un_zipped as zf:\n",
    "#     for file in zf.namelist():\n",
    "#         print(file)\n",
    "#         # not in root directory, pass, otherwise save\n",
    "#         if file.startswith('_'):\n",
    "#             pass\n",
    "#         else:\n",
    "#             zf.extract(file, root)\n",
    "#             result_files.append(result_file)\n",
    "##STOP         \n",
    "                \n",
    "# with un_zipped as zf:\n",
    "#     for file in zf.namelist():\n",
    "#         print(file)\n",
    "#         if file.startswith('20'):\n",
    "#             zf.extract(file, root)\n",
    "#             result_files.append(result_file)\n",
    "\n",
    "\n",
    "# # unzipfolder.extract(file, root)\n",
    "# for file in unzipfolder:\n",
    "#     if file.endswith('.csv'):\n",
    "#         unzipfolder.extract(file, root)\n",
    "#         print(file)\n",
    "#         result_files.append(file)\n",
    "\n",
    "# for file in os.listdir(root):\n",
    "#     if os.path.isfile(os.path.join(root, file)):\n",
    "#         result_file = os.path.join(root, file)\n",
    "#         if result_file.endswith('.csv'):\n",
    "#             print(result_file)\n",
    "#             result_files.append(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0eb819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources\n"
     ]
    }
   ],
   "source": [
    "# Function to rename files for clarity and easier looping\n",
    "def main():\n",
    "    for i, file in enumerate(os.listdir(root)):\n",
    "        print(root)\n",
    "        source = f'{root}/{result_files[i]}'\n",
    "        destination = f'{root}/{rename_files[i]}'\n",
    "        os.rename(source, destination)\n",
    "# Driver Code\n",
    "if __name__ == '__main__':     \n",
    "    # Calling main() function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408e305a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013-07 - Citi Bike trip data.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe45d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['201307.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b0620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedfbe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92784d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(result_files[0])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in result_files:\n",
    "#     df2 = pd.read_csv(url2, compression = 'zip', engine ='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(result_files[1])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "  \n",
    "# time taken to read data\n",
    "s_time_chunk = time.time()\n",
    "chunk = pd.read_csv('gender_voice_dataset.csv', chunksize=1000)\n",
    "e_time_chunk = time.time()\n",
    "  \n",
    "print(\"With chunks: \", (e_time_chunk-s_time_chunk), \"sec\")\n",
    "df = pd.concat(chunk)\n",
    "  \n",
    "# data\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b90d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using dask docomentation/code from https://www.geeksforgeeks.org/working-with-large-csv-files-in-python/\n",
    "# import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from dask import dataframe as df1\n",
    "  \n",
    "# time taken to read data\n",
    "s_time_dask = time.time()\n",
    "dask_df = df1.read_csv('gender_voice_dataset.csv')\n",
    "e_time_dask = time.time()\n",
    "  \n",
    "print(\"Read with dask: \", (e_time_dask-s_time_dask), \"seconds\")\n",
    "  \n",
    "# data\n",
    "dask_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
